{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 14774,
          "databundleVersionId": 875431,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harshkotkar/Deep-Learning/blob/main/APTOS_Eye_Preprocessing_in_Diabetic_Retinopathy(full_and_final_).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# # IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# # RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "# import kagglehub\n",
        "# kagglehub.login()\n"
      ],
      "metadata": {
        "id": "-tvpMg4FA_wF"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 30
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "aptos2019_blindness_detection_path = kagglehub.competition_download('aptos2019-blindness-detection')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "pdraKDaUA_wJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c613081b-38f8-40a7-8388-463897be4231"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/competitions/data/download-all/aptos2019-blindness-detection...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.51G/9.51G [00:54<00:00, 189MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        " # This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-23T17:36:35.060647Z",
          "iopub.execute_input": "2025-08-23T17:36:35.060857Z",
          "iopub.status.idle": "2025-08-23T17:36:45.258068Z",
          "shell.execute_reply.started": "2025-08-23T17:36:35.060838Z",
          "shell.execute_reply": "2025-08-23T17:36:45.25707Z"
        },
        "id": "vzckUeffA_wK"
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n"
      ],
      "metadata": {
        "id": "L0Xrbln53oks"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(aptos2019_blindness_detection_path)  # This shows the base folder\n",
        "print(os.listdir(aptos2019_blindness_detection_path))  # List what’s inside\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPByTQ9dE9Fr",
        "outputId": "a48f8a7b-e156-4632-9d6a-564a80338045"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.cache/kagglehub/competitions/aptos2019-blindness-detection\n",
            "['train_images', 'train.csv', 'test.csv', 'test_images', 'sample_submission.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Base dataset path\n",
        "base_path = \"/root/.cache/kagglehub/competitions/aptos2019-blindness-detection\"\n",
        "\n",
        "# Load CSVs\n",
        "train_df = pd.read_csv(os.path.join(base_path, \"train.csv\"))\n",
        "test_df = pd.read_csv(os.path.join(base_path, \"test.csv\"))\n",
        "\n",
        "print(train_df.head())\n",
        "print(test_df.head())\n"
      ],
      "metadata": {
        "id": "2xrqPNVhJtd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdb1168d-ae29-4205-a527-262eeecfcf3b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        id_code  diagnosis\n",
            "0  000c1434d8d7          2\n",
            "1  001639a390f0          4\n",
            "2  0024cdab0c1e          1\n",
            "3  002c21358ce6          0\n",
            "4  005b95c28852          0\n",
            "        id_code\n",
            "0  0005cfc8afb6\n",
            "1  003f0afdcd15\n",
            "2  006efc72b638\n",
            "3  00836aaacf06\n",
            "4  009245722fa4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_path = os.path.join(base_path, \"train_images\")\n",
        "test_images_path  = os.path.join(base_path, \"test_images\")\n"
      ],
      "metadata": {
        "id": "W8Vm5OlhFN8o"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Why tf.data? Efficient handling of large image datasets → parallelism + prefetching.\n",
        "\n",
        "Why resize to (224×224)? Most pretrained CNN backbones (ResNet, EfficientNet, Inception) expect 224×224 inputs. Keeping consistency allows us to later plug in pretrained models easily.\n",
        "\n",
        "Why normalize (0–1)? Neural nets converge faster when input values are small and consistent. Images originally have pixel values 0–255; dividing by 255 standardizes them. New section"
      ],
      "metadata": {
        "id": "upocOVtKOlOb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AiTDHOZo3OMy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kx8ipnk33Oav"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "33JJeyGK3OeB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "train_imgs = \"/root/.cache/kagglehub/competitions/aptos2019-blindness-detection/train_images\"\n",
        "\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def load_image(img_id, label):\n",
        "    # Create image path using tf.strings.join\n",
        "    img_path = tf.strings.join([train_imgs, \"/\", img_id, \".png\"])\n",
        "\n",
        "    # Read image file\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
        "    img = img / 255.0  # normalize\n",
        "\n",
        "    return img, label\n",
        "\n",
        "# Convert dataset\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_df['id_code'].values,\n",
        "                                               train_df['diagnosis'].values))\n",
        "train_ds = train_ds.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.shuffle(1024).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "hheluJqTJK1A"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Test Split"
      ],
      "metadata": {
        "id": "IUzo7u2RPDCx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##why do we not do the X_train ,Y_train, that one split?\n",
        "### Our Case (APTOS Dataset)\n",
        "\n",
        "Our dataframe looks like this:\n",
        "\n",
        "id_code         \tdiagnosis\n",
        "000c1434d8d7\t       2\n",
        "001639a390f0\t       4\n",
        "0024cdab0c1e\t       1\n",
        "id_code → not really a feature, it’s just the filename of the image.\n",
        "\n",
        "diagnosis → the label (0–4).\n",
        "\n",
        "\n",
        "##In this dataset, the dataframe doesn’t directly contain the features (images).\n",
        "\n",
        "##Instead, it maps id_code (filename) → diagnosis (label).\n",
        "\n",
        "##We split the dataframe rows while keeping both columns, then later load the actual images using those filenames."
      ],
      "metadata": {
        "id": "ouyEcGfARj9m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Why stratify?\n",
        "Because the dataset is imbalanced (some disease classes are rarer). stratify ensures both train and validation have similar class distributions."
      ],
      "metadata": {
        "id": "8_yM2PwMPd48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Train-validation split\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['diagnosis'], random_state=42)\n",
        "\n",
        "print(\"Training samples:\", len(train_df))\n",
        "print(\"Validation samples:\", len(val_df))\n",
        "train_df.hist()\n",
        "val_df.hist()"
      ],
      "metadata": {
        "id": "ZgsOhhL0JXL6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "outputId": "6a492cb2-c31e-40e3-808a-afb196aabfd3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 2343\n",
            "Validation samples: 586\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<Axes: title={'center': 'diagnosis'}>]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bFBpU-P93fMr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /root/.cache/kagglehub/competitions/aptos2019-blindness-detection/train_images | head -20\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn_q2Zzpcguy",
        "outputId": "e6a6d891-dfe8-4242-d52d-af6e80025507"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "000c1434d8d7.png\n",
            "001639a390f0.png\n",
            "0024cdab0c1e.png\n",
            "002c21358ce6.png\n",
            "005b95c28852.png\n",
            "0083ee8054ee.png\n",
            "0097f532ac9f.png\n",
            "00a8624548a9.png\n",
            "00b74780d31d.png\n",
            "00cb6555d108.png\n",
            "00cc2b75cddd.png\n",
            "00e4ddff966a.png\n",
            "00f6c1be5a33.png\n",
            "0104b032c141.png\n",
            "0124dffecf29.png\n",
            "0125fbd2e791.png\n",
            "012a242ac6ff.png\n",
            "014508ccb9cb.png\n",
            "0151781fe50b.png\n",
            "0161338f53cc.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "12an7OuPfOhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_imgs = \"/root/.cache/kagglehub/competitions/aptos2019-blindness-detection/train_images\"\n",
        "\n",
        "# # Fix filenames to match actual files\n",
        "# train_df[\"id_code\"] = train_df[\"id_code\"].astype(str) + \".png\"\n",
        "# test_df[\"id_code\"]  = test_df[\"id_code\"].astype(str) + \".png\"\n",
        "\n",
        "# # ImageDataGenerator\n",
        "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# train_datagen = ImageDataGenerator(validation_split=0.2, rescale=1./255)\n",
        "\n",
        "# train_generator = train_datagen.flow_from_dataframe(\n",
        "#     dataframe=train_df,\n",
        "#     directory=\"/root/.cache/kagglehub/competitions/aptos2019-blindness-detection/train_images\",\n",
        "#     x_col=\"id_code\",\n",
        "#     y_col=\"diagnosis\",\n",
        "#     subset=\"training\",\n",
        "#     batch_size=32,\n",
        "#     seed=42,\n",
        "#     shuffle=True,\n",
        "#     class_mode=\"categorical\",\n",
        "#     target_size=(224, 224))\n",
        "\n",
        "# valid_generator = train_datagen.flow_from_dataframe(\n",
        "#     dataframe=train_df,\n",
        "#     directory=\"/root/.cache/kagglehub/competitions/aptos2019-blindness-detection/train_images\",\n",
        "#     x_col=\"id_code\",\n",
        "#     y_col=\"diagnosis\",\n",
        "#     subset=\"validation\",\n",
        "#     batch_size=32,\n",
        "#     seed=42,\n",
        "#     shuffle=True,\n",
        "#     class_mode=\"categorical\",\n",
        "#     target_size=(224, 224))\n",
        "\n"
      ],
      "metadata": {
        "id": "h7jhNKB3dF5Q"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"id_code\"] = train_df[\"id_code\"].str.replace(r\"(\\.png)+$\", \".png\", regex=True)\n",
        "test_df[\"id_code\"]  = test_df[\"id_code\"].str.replace(r\"(\\.png)+$\", \".png\", regex=True)\n",
        "\n",
        "# train_df[\"id_code\"] = train_df[\"id_code\"].str.replace(r\"(\\.png)+$\", \".png\", regex=True)\n",
        "# test_df[\"id_code\"]  = test_df[\"id_code\"].str.replace(r\"(\\.png)+$\", \".png\", regex=True)\n",
        "\n",
        "# Train-validation split\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['diagnosis'], random_state=42)\n",
        "\n",
        "# Define dataset loader\n",
        "def load_image(img_id, label):\n",
        "    img_path = tf.strings.join([train_imgs, \"/\", img_id])\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
        "    img = img / 255.0\n",
        "    return img, label\n",
        "\n",
        "# Create datasets\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_df[\"id_code\"].values, train_df[\"diagnosis\"].values))\n",
        "train_ds = train_ds.map(load_image, num_parallel_calls=tf.data.AUTOTUNE).shuffle(1024).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((val_df[\"id_code\"].values, val_df[\"diagnosis\"].values))\n",
        "val_ds = val_ds.map(load_image, num_parallel_calls=tf.data.AUTOTUNE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "959KJZhrgAnk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "train_imgs = \"/root/.cache/kagglehub/competitions/aptos2019-blindness-detection/train_images\"\n",
        "files = os.listdir(train_imgs)\n",
        "print(\"Total files in train_images:\", len(files))\n",
        "print(\"First 10 files:\", files[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkIzqNB0e-oi",
        "outputId": "6c30244c-fc87-4f20-8f73-6aa28831a713"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total files in train_images: 3662\n",
            "First 10 files: ['a3b2e93d058b.png', '936299166bea.png', '5b3d41626ec5.png', '172df1330a60.png', '25d069089c5e.png', '504a69096fcb.png', 'cd5714db652d.png', 'cd1c98ec48b1.png', '7f1f3269f546.png', 'a30a143a53a3.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if all image names exist in train_images folder\n",
        "missing_files = [f for f in train_df[\"id_code\"].values if f not in files]\n",
        "print(\"Missing files:\", len(missing_files))\n",
        "print(missing_files[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODeTwreRfE9O",
        "outputId": "67079cab-63dd-418c-a42b-115a406c216f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing files: 1199\n",
            "['a8582e346df0', '0dce95217626', '842d697884f6', '6dc0281f11e3', '1116271db4ea', 'f0e1201b5c1f', 'ef26625121b3', '9eaf735cf01f', '16ce555748d8', '9e99ae6ee7af']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Simple CNN Model\n",
        "\n",
        "model = models.Sequential([\n",
        "        layers.Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3)),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "\n",
        "        layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "\n",
        "        layers.Conv2D(128, (3,3), activation='relu'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(5, activation='softmax')\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLfXMJFBPLRQ",
        "outputId": "6dde045c-c251-4238-e6a6-6fd1c19409ce"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "#conv2d_4\n",
        "#Kh=kernal heingt,Kw=kernal width, Cin=chanel input as rgb it  is 3 and grayscal is 1\n",
        "#(Kh x Kw x Cin x Cout )+Cout\n",
        "#(3×3×32×64)+64=(18,432)+64=18,496"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "FKcCfeXkXHfP",
        "outputId": "ea0b3ca0-82ca-4c4d-bca8-671162820a98"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86528\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m11,075,712\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m645\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86528</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">11,075,712</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,169,605\u001b[0m (42.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,169,605</span> (42.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,169,605\u001b[0m (42.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,169,605</span> (42.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(train_ds,\n",
        "                  validation_data=val_ds,\n",
        "                  epochs=10,\n",
        "                  verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "id": "UjbVAc80Xsvy",
        "outputId": "6fb386e2-4c22-4384-a117-4468750bdd54"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "Graph execution error:\n\nDetected at node ReadFile defined at (most recent call last):\n<stack traces unavailable>\nDetected at node ReadFile defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) NOT_FOUND:  Error in user-defined function passed to ParallelMapDatasetV2:15 transformation with iterator: Iterator::Root::Prefetch::BatchV2::Shuffle::ParallelMapV2: /root/.cache/kagglehub/competitions/aptos2019-blindness-detection/train_images/9a326446c431; No such file or directory\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) NOT_FOUND:  Error in user-defined function passed to ParallelMapDatasetV2:15 transformation with iterator: Iterator::Root::Prefetch::BatchV2::Shuffle::ParallelMapV2: /root/.cache/kagglehub/competitions/aptos2019-blindness-detection/train_images/9a326446c431; No such file or directory\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_multi_step_on_iterator_2156]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3464727458.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history=model.fit(train_ds,\n\u001b[0m\u001b[1;32m      2\u001b[0m                   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   verbose=1)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Graph execution error:\n\nDetected at node ReadFile defined at (most recent call last):\n<stack traces unavailable>\nDetected at node ReadFile defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) NOT_FOUND:  Error in user-defined function passed to ParallelMapDatasetV2:15 transformation with iterator: Iterator::Root::Prefetch::BatchV2::Shuffle::ParallelMapV2: /root/.cache/kagglehub/competitions/aptos2019-blindness-detection/train_images/9a326446c431; No such file or directory\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) NOT_FOUND:  Error in user-defined function passed to ParallelMapDatasetV2:15 transformation with iterator: Iterator::Root::Prefetch::BatchV2::Shuffle::ParallelMapV2: /root/.cache/kagglehub/competitions/aptos2019-blindness-detection/train_images/9a326446c431; No such file or directory\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_multi_step_on_iterator_2156]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##verbose determines how much information the computer displays during the process.\n",
        "verbose=0 means no output. The computer will not show any progress until the process is complete.\n",
        "verbose=1 means a progress bar is shown. The computer displays a bar that updates as the training progresses, along with a summary at the end of each pass through the data (epoch).\n",
        "verbose=2 means only the summary is shown. The computer only prints a line with the results at the end of each epoch"
      ],
      "metadata": {
        "id": "p4UrfxyNkHsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_acc = model.evaluate(val_ds, verbose=1)\n",
        "print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
        "print(f\"Validation Loss: {val_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "Gthz1UTHamFC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "outputId": "8d4c3287-7f31-4619-d258-63fb5767bdfd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "Graph execution error:\n\nDetected at node ReadFile defined at (most recent call last):\n<stack traces unavailable>\nDetected at node ReadFile defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) NOT_FOUND:  /root/.cache/kagglehub/competitions/aptos2019-blindness-detection/train_images/191348830ddf; No such file or directory\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) NOT_FOUND:  /root/.cache/kagglehub/competitions/aptos2019-blindness-detection/train_images/191348830ddf; No such file or directory\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_multi_step_on_iterator_2279]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4224199533.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Validation Accuracy: {val_acc:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Validation Loss: {val_loss:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Graph execution error:\n\nDetected at node ReadFile defined at (most recent call last):\n<stack traces unavailable>\nDetected at node ReadFile defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) NOT_FOUND:  /root/.cache/kagglehub/competitions/aptos2019-blindness-detection/train_images/191348830ddf; No such file or directory\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) NOT_FOUND:  /root/.cache/kagglehub/competitions/aptos2019-blindness-detection/train_images/191348830ddf; No such file or directory\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_multi_step_on_iterator_2279]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for images, labels in val_ds:   # loop through batches\n",
        "    preds = model.predict(images, verbose=0)\n",
        "    y_pred.extend(np.argmax(preds, axis=1))\n",
        "    y_true.extend(labels.numpy())   # no argmax, already integers\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "# Classification report\n",
        "from sklearn.metrics import classification_report, confusion_matrix, cohen_kappa_score\n",
        "print(classification_report(y_true, y_pred, digits=4))\n",
        "\n",
        "# Confusion matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix - Validation Set\")\n",
        "plt.show()\n",
        "\n",
        "# Quadratic Weighted Kappa\n",
        "kappa = cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
        "print(\"Quadratic Weighted Kappa:\", kappa)\n"
      ],
      "metadata": {
        "id": "jcrIOIzmztQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = \"/root/.cache/kagglehub/competitions/aptos2019-blindness-detection\"\n",
        "train_imgs = os.path.join(base_path, \"train_images\")"
      ],
      "metadata": {
        "id": "8yGDDkbpz35y"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(os.path.join(base_path, \"train.csv\"))\n",
        "test_df = pd.read_csv(os.path.join(base_path, \"test.csv\"))"
      ],
      "metadata": {
        "id": "jnGCiBfTTB_V"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"id_code\"] = train_df[\"id_code\"].str.replace(r\"(\\.png)+$\", \".png\", regex=True)\n",
        "test_df[\"id_code\"]  = test_df[\"id_code\"].str.replace(r\"(\\.png)+$\", \".png\", regex=True)\n"
      ],
      "metadata": {
        "id": "QrWKqmV6TEJj"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['diagnosis'], random_state=42)\n"
      ],
      "metadata": {
        "id": "q4qu33zjTGw3"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset loader\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def load_image(img_id, label):\n",
        "    img_path = tf.strings.join([train_imgs, \"/\", img_id])\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
        "    img = img / 255.0\n",
        "    return img, label\n"
      ],
      "metadata": {
        "id": "HAkiuI0DTKFt"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lV4DtwurTNLx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}