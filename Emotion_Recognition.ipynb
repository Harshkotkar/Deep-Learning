{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 4140,
          "sourceType": "datasetVersion",
          "datasetId": 2477
        },
        {
          "sourceId": 742210,
          "sourceType": "datasetVersion",
          "datasetId": 17
        },
        {
          "sourceId": 800230,
          "sourceType": "datasetVersion",
          "datasetId": 1305
        },
        {
          "sourceId": 2510329,
          "sourceType": "datasetVersion",
          "datasetId": 1520310
        },
        {
          "sourceId": 2617192,
          "sourceType": "datasetVersion",
          "datasetId": 1590810
        }
      ],
      "dockerImageVersionId": 30587,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Emotion Recognition",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harshkotkar/Deep-Learning/blob/main/Emotion_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "kazanova_sentiment140_path = kagglehub.dataset_download('kazanova/sentiment140')\n",
        "crowdflower_twitter_airline_sentiment_path = kagglehub.dataset_download('crowdflower/twitter-airline-sentiment')\n",
        "bittlingmayer_amazonreviews_path = kagglehub.dataset_download('bittlingmayer/amazonreviews')\n",
        "jp797498e_twitter_entity_sentiment_analysis_path = kagglehub.dataset_download('jp797498e/twitter-entity-sentiment-analysis')\n",
        "parulpandey_emotion_dataset_path = kagglehub.dataset_download('parulpandey/emotion-dataset')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "DPOjA4-bPSaM"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "![SENTIMENT-09-1.png](attachment:504e696e-f893-4788-8962-2c574d2841f7.png)"
      ],
      "metadata": {
        "id": "vsPYrgh2PSaP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* <b> Overview :</b> Explore text-based emotion recognition, a dynamic field in <span style=\"background-color: red; padding: 4px; border-radius:5px;\">NLP</span>, focusing on deciphering diverse emotional states in textual content.\n",
        "\n",
        "* <b> Objective :</b> Build a system for automatic categorization of text into six emotions\n",
        "( <span style=\"color: #F8DE22;\">joy</span>  ,\n",
        " <span style=\"color: #0c0d49;\">sadness</span> ,\n",
        " <span style=\"color: #b82f2f;\">fear</span> ,\n",
        " <span style=\"color: #331e1e;\">anger</span > ,\n",
        " <span style=\"color: red;\">love</span> ,\n",
        " <span style=\"color: #00fff7;\">surprise</span>)\n",
        "* <b> Model Choice : </b> Utilize <span style=\"background-color: #F8DE22; padding: 4px; border-radius:5px;\">LSTM</span>\n",
        " (Long Short-Term Memory) networks, a type of <span style=\"background-color: #F8DE22; padding: 4px; border-radius:5px;\">RNN</span>.\n",
        "\n",
        "* <b> Implementation : </b>\n",
        "Implemented with <span style=\"background-color: #F8DE22; padding: 4px; border-radius:5px;\">TensorFlow</span>.\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T13:58:52.710537Z",
          "iopub.execute_input": "2023-12-09T13:58:52.710981Z",
          "iopub.status.idle": "2023-12-09T13:58:52.720741Z",
          "shell.execute_reply.started": "2023-12-09T13:58:52.710948Z",
          "shell.execute_reply": "2023-12-09T13:58:52.719287Z"
        },
        "id": "QSn4_6vAPSaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from wordcloud import WordCloud\n",
        "from nltk.stem import PorterStemmer\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-12-09T23:34:03.237173Z",
          "iopub.execute_input": "2023-12-09T23:34:03.237745Z",
          "iopub.status.idle": "2023-12-09T23:34:03.24873Z",
          "shell.execute_reply.started": "2023-12-09T23:34:03.237623Z",
          "shell.execute_reply": "2023-12-09T23:34:03.247276Z"
        },
        "trusted": true,
        "id": "jjUHgfCSPSaR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 | The Dataset"
      ],
      "metadata": {
        "id": "y5-cLLCHPSaR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* any data sets involving sentiment analysis are <span style=\"background-color: #F8DE22; padding: 2px; border-radius:5px;\">binary classification</span> problems\n",
        "* In this dataset we have <span style=\"background-color: #F8DE22; padding: 2px; border-radius:5px;\">6 different sentiments</span> , which means we'll be treating this problem as a <span style=\"background-color: #F8DE22; padding: 2px; border-radius:5px;\">multiclass classification</span> problem"
      ],
      "metadata": {
        "id": "MdRN202rPSaS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "   ### 1. 1 | Loading Data"
      ],
      "metadata": {
        "id": "s4mV7ONvPSaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = pd.read_csv('/kaggle/input/emotion-dataset/validation.csv')\n",
        "train_data = pd.read_csv('/kaggle/input/emotion-dataset/training.csv')\n",
        "test_data = pd.read_csv('/kaggle/input/emotion-dataset/test.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T23:34:03.251149Z",
          "iopub.execute_input": "2023-12-09T23:34:03.251558Z",
          "iopub.status.idle": "2023-12-09T23:34:03.345772Z",
          "shell.execute_reply.started": "2023-12-09T23:34:03.251523Z",
          "shell.execute_reply": "2023-12-09T23:34:03.344402Z"
        },
        "trusted": true,
        "id": "zYD5BfpjPSaS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Validation data :\",val_data.shape)\n",
        "print(\"Train data :\",train_data.shape)\n",
        "print(\"Test data :\",test_data.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T23:34:03.347347Z",
          "iopub.execute_input": "2023-12-09T23:34:03.347746Z",
          "iopub.status.idle": "2023-12-09T23:34:03.355223Z",
          "shell.execute_reply.started": "2023-12-09T23:34:03.347709Z",
          "shell.execute_reply": "2023-12-09T23:34:03.353914Z"
        },
        "trusted": true,
        "id": "VgVivXjMPSaU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "* There is a lot of data in test, in my case i divided it and put the est in the val_data"
      ],
      "metadata": {
        "id": "tc_YKIUoPSaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "half_test_data = test_data.iloc[1000:]\n",
        "test_data = test_data.iloc[:1000]\n",
        "\n",
        "val_data = pd.concat([val_data, half_test_data], axis=0)\n",
        "\n",
        "print(\"new Vald data :\",val_data.shape)\n",
        "print(\"new Test data :\",test_data.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T23:34:03.357011Z",
          "iopub.execute_input": "2023-12-09T23:34:03.357487Z",
          "iopub.status.idle": "2023-12-09T23:34:03.37186Z",
          "shell.execute_reply.started": "2023-12-09T23:34:03.357439Z",
          "shell.execute_reply": "2023-12-09T23:34:03.370895Z"
        },
        "trusted": true,
        "id": "Js19vLCnPSaV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head(10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T23:34:03.375599Z",
          "iopub.execute_input": "2023-12-09T23:34:03.376371Z",
          "iopub.status.idle": "2023-12-09T23:34:03.394234Z",
          "shell.execute_reply.started": "2023-12-09T23:34:03.376334Z",
          "shell.execute_reply": "2023-12-09T23:34:03.392854Z"
        },
        "trusted": true,
        "id": "yv48MIcbPSaV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 2 | Adding Label Data"
      ],
      "metadata": {
        "id": "kWs4RgeRPSaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_dict = {0:'sadness', 1:'joy', 2:'love', 3:'anger', 4:'fear', 5:'surprise'}\n",
        "train_data['label_name'] = train_data['label'].map(labels_dict)\n",
        "train_data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T23:34:03.396239Z",
          "iopub.execute_input": "2023-12-09T23:34:03.396639Z",
          "iopub.status.idle": "2023-12-09T23:34:03.422261Z",
          "shell.execute_reply.started": "2023-12-09T23:34:03.396601Z",
          "shell.execute_reply": "2023-12-09T23:34:03.421147Z"
        },
        "trusted": true,
        "id": "dgxXPxsvPSaW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.groupby([\"label_name\",\"label\"]).size()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T23:34:03.424263Z",
          "iopub.execute_input": "2023-12-09T23:34:03.425174Z",
          "iopub.status.idle": "2023-12-09T23:34:03.454741Z",
          "shell.execute_reply.started": "2023-12-09T23:34:03.425129Z",
          "shell.execute_reply": "2023-12-09T23:34:03.453398Z"
        },
        "trusted": true,
        "id": "kL-4SCFKPSaW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 3 | Data Visualization"
      ],
      "metadata": {
        "id": "EmSI_s6-PSaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[\"label_name\"].value_counts().plot(kind='bar',color=['yellow', '#0c0d49', '#b82f2f', '#331e1e', 'red','#00fff7'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T23:34:03.456687Z",
          "iopub.execute_input": "2023-12-09T23:34:03.457209Z",
          "iopub.status.idle": "2023-12-09T23:34:04.656602Z",
          "shell.execute_reply.started": "2023-12-09T23:34:03.457161Z",
          "shell.execute_reply": "2023-12-09T23:34:04.655499Z"
        },
        "trusted": true,
        "id": "kE1gHhqVPSaY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 | Data Cleaning"
      ],
      "metadata": {
        "id": "IMSHWeeFPSaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.isnull().sum())\n",
        "print(val_data.isnull().sum())\n",
        "print(test_data.isnull().sum())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T23:34:04.657896Z",
          "iopub.execute_input": "2023-12-09T23:34:04.658225Z",
          "iopub.status.idle": "2023-12-09T23:34:04.673623Z",
          "shell.execute_reply.started": "2023-12-09T23:34:04.658196Z",
          "shell.execute_reply": "2023-12-09T23:34:04.672362Z"
        },
        "trusted": true,
        "id": "nUBK-3B9PSaY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 | Tokenisation & Stemming"
      ],
      "metadata": {
        "id": "OCuJt7FKPSaY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* <span style=\"background-color: #F8DE22; padding: 2px; border-radius:5px;\">Tokenization</span> assigns unique IDs to words, creating a word index or vocabulary.\n",
        "* <b>Example Sentence :</b> \"Tokenization is essential for NLP tasks.\"\n",
        "* <b>Tokenized Output : </b>['Tokenization', 'is', 'essential', 'for', 'NLP', 'tasks', '.']\n",
        "\n",
        "\n",
        "* <span style=\"background-color: #F8DE22; padding: 2px; border-radius:5px;\">Stemming</span> is a technique used to reduce an inflected word down to its word stem.\n",
        "* <b>Example :</b>\n",
        "* <b>Original Words :</b> running , programming , swimming , happiness , programmer <span style=\"background-color: #F8DE22; padding: 2px; border-radius:5px;\">  (5 words)</span>\n",
        "* <b>Stemmed Words :</b> run , program , swim , happi   <span style=\"background-color: #F8DE22; padding: 2px; border-radius:5px;\">  (4 words)</span>"
      ],
      "metadata": {
        "id": "z6GYk9bvPSaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_list = train_data['text'].tolist() + test_data['text'].tolist() + val_data['text'].tolist()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T23:34:04.675633Z",
          "iopub.execute_input": "2023-12-09T23:34:04.676124Z",
          "iopub.status.idle": "2023-12-09T23:34:04.688872Z",
          "shell.execute_reply.started": "2023-12-09T23:34:04.676079Z",
          "shell.execute_reply": "2023-12-09T23:34:04.687576Z"
        },
        "trusted": true,
        "id": "e624Z1SoPSaZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer1 = Tokenizer()\n",
        "tokenizer1.fit_on_texts(all_list)\n",
        "word_index1 = tokenizer1.word_index\n",
        "\n",
        "print(\"Nombre of words without Stemming:\",len(word_index1))\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in word_index1.keys()]\n",
        "\n",
        "tokenizer2 = Tokenizer()\n",
        "tokenizer2.fit_on_texts(stemmed_words)\n",
        "word_index2 = tokenizer2.word_index\n",
        "\n",
        "print(\"Nombre of words with Stemming:\",len(word_index2))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T23:34:04.690559Z",
          "iopub.execute_input": "2023-12-09T23:34:04.690981Z",
          "iopub.status.idle": "2023-12-09T23:34:06.216641Z",
          "shell.execute_reply.started": "2023-12-09T23:34:04.690934Z",
          "shell.execute_reply": "2023-12-09T23:34:06.215344Z"
        },
        "trusted": true,
        "id": "Z97GiS2ZPSaZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "* load all data to list : <b>[ [ Tokenised_Data ] , label ] </b>"
      ],
      "metadata": {
        "id": "Cl0RPx-2PSaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(data):\n",
        "    new_data = []\n",
        "    for index, row in data.iterrows():\n",
        "        test_split = row['text'].split()\n",
        "        stemmed_words2 = [stemmer.stem(word) for word in test_split]\n",
        "        token_list= tokenizer2.texts_to_sequences([stemmed_words2])[0]\n",
        "        new_data.append([token_list,row['label']])\n",
        "    return new_data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T23:34:06.218201Z",
          "iopub.execute_input": "2023-12-09T23:34:06.218635Z",
          "iopub.status.idle": "2023-12-09T23:34:06.226738Z",
          "shell.execute_reply.started": "2023-12-09T23:34:06.218592Z",
          "shell.execute_reply": "2023-12-09T23:34:06.225408Z"
        },
        "trusted": true,
        "id": "80ba_3Z0PSaa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "new_train_data = preprocess_data(train_data)\n",
        "print(train_data['text'][0])\n",
        "print(new_train_data[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T23:34:06.228327Z",
          "iopub.execute_input": "2023-12-09T23:34:06.228783Z",
          "iopub.status.idle": "2023-12-09T23:34:17.142945Z",
          "shell.execute_reply.started": "2023-12-09T23:34:06.228748Z",
          "shell.execute_reply": "2023-12-09T23:34:17.141743Z"
        },
        "trusted": true,
        "id": "3F95KVjzPSaa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "new_val_data = preprocess_data(val_data)\n",
        "print(val_data['text'][0])\n",
        "print(new_val_data[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T23:34:17.150267Z",
          "iopub.execute_input": "2023-12-09T23:34:17.150654Z",
          "iopub.status.idle": "2023-12-09T23:34:19.245497Z",
          "shell.execute_reply.started": "2023-12-09T23:34:17.150622Z",
          "shell.execute_reply": "2023-12-09T23:34:19.24406Z"
        },
        "trusted": true,
        "id": "gTs2WN49PSaa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting into train_X and train_y\n",
        "train_X = [row[0] for row in new_train_data]\n",
        "train_y = [row[1] for row in new_train_data]\n",
        "\n",
        "# Print the results\n",
        "print(\"train_X:\", train_X[0])\n",
        "print(\"train_y:\", train_y[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T23:34:19.247091Z",
          "iopub.execute_input": "2023-12-09T23:34:19.247558Z",
          "iopub.status.idle": "2023-12-09T23:34:19.258603Z",
          "shell.execute_reply.started": "2023-12-09T23:34:19.247512Z",
          "shell.execute_reply": "2023-12-09T23:34:19.257499Z"
        },
        "trusted": true,
        "id": "SpyvNuWdPSaa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "val_X = [row[0] for row in new_val_data]\n",
        "val_y = [row[1] for row in new_val_data]\n",
        "\n",
        "print(\"train_X:\", val_X[0])\n",
        "print(\"train_y:\", val_y[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T23:34:19.260145Z",
          "iopub.execute_input": "2023-12-09T23:34:19.261187Z",
          "iopub.status.idle": "2023-12-09T23:34:19.26962Z",
          "shell.execute_reply.started": "2023-12-09T23:34:19.261119Z",
          "shell.execute_reply": "2023-12-09T23:34:19.268682Z"
        },
        "trusted": true,
        "id": "cM1CRWIzPSab"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. 2 | Add Padding"
      ],
      "metadata": {
        "id": "PnN5Nt5vPSab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "length_of_longest_sentence = len(max(train_X, key=len))\n",
        "print(length_of_longest_sentence)\n",
        "print(max(train_X, key=len))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T23:34:19.27079Z",
          "iopub.execute_input": "2023-12-09T23:34:19.271193Z",
          "iopub.status.idle": "2023-12-09T23:34:19.289427Z",
          "shell.execute_reply.started": "2023-12-09T23:34:19.271163Z",
          "shell.execute_reply": "2023-12-09T23:34:19.288184Z"
        },
        "trusted": true,
        "id": "YvfNkQpzPSab"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(train_X)):\n",
        "    for j in range(length_of_longest_sentence-len(train_X[i])):\n",
        "        train_X[i].append(0)\n",
        "\n",
        "for i in range(len(val_X)):\n",
        "    for j in range(length_of_longest_sentence-len(val_X[i])):\n",
        "        val_X[i].append(0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T23:34:19.291569Z",
          "iopub.execute_input": "2023-12-09T23:34:19.292057Z",
          "iopub.status.idle": "2023-12-09T23:34:19.504825Z",
          "shell.execute_reply.started": "2023-12-09T23:34:19.292014Z",
          "shell.execute_reply": "2023-12-09T23:34:19.503478Z"
        },
        "trusted": true,
        "id": "xq_UjQAtPSab"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. 3 | List to Array (numpy)"
      ],
      "metadata": {
        "id": "IlylykWHPSab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = np.array(train_X)\n",
        "train_y = np.array(train_y)\n",
        "val_X = np.array(val_X)\n",
        "val_y = np.array(val_y)\n",
        "\n",
        "print(train_X.shape,train_y.shape)\n",
        "print(val_X.shape,val_y.shape)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T23:34:19.50644Z",
          "iopub.execute_input": "2023-12-09T23:34:19.506823Z",
          "iopub.status.idle": "2023-12-09T23:34:19.706661Z",
          "shell.execute_reply.started": "2023-12-09T23:34:19.50679Z",
          "shell.execute_reply": "2023-12-09T23:34:19.705465Z"
        },
        "trusted": true,
        "id": "WUfCkEdsPSac"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to one-hot encoding\n",
        "train_y_one_hot = to_categorical(train_y, num_classes=16000)\n",
        "val_y_one_hot = to_categorical(val_y, num_classes=16000)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T23:34:19.708608Z",
          "iopub.execute_input": "2023-12-09T23:34:19.709071Z",
          "iopub.status.idle": "2023-12-09T23:34:20.070019Z",
          "shell.execute_reply.started": "2023-12-09T23:34:19.709033Z",
          "shell.execute_reply": "2023-12-09T23:34:20.068962Z"
        },
        "trusted": true,
        "id": "E0k0CVyiPSac"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 | Create model (LSTM)"
      ],
      "metadata": {
        "id": "2wry5bJyPSac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. 1 | Architechture of Bidirectional LSTM Neural Network"
      ],
      "metadata": {
        "id": "QZkdoXfzPSac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![download.png](attachment:e3218baf-2240-45f3-8aac-e6956af5346e.png)"
      ],
      "metadata": {
        "id": "6mqJ5u8dPSac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. 2 | Bi- LSTM Neural Network Model training"
      ],
      "metadata": {
        "id": "zD20dj9NPSad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(16000, 100, input_length=66))\n",
        "model.add(Bidirectional(LSTM(150)))\n",
        "model.add(Dense(16000, activation='softmax'))\n",
        "adam = Adam(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "history = model.fit(train_X, train_y_one_hot, epochs=25, verbose=1,validation_data=(val_X,val_y_one_hot))\n",
        "#print model.summary()\n",
        "print(model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-09T23:34:20.071762Z",
          "iopub.execute_input": "2023-12-09T23:34:20.072253Z",
          "iopub.status.idle": "2023-12-10T00:07:40.037112Z",
          "shell.execute_reply.started": "2023-12-09T23:34:20.072209Z",
          "shell.execute_reply": "2023-12-10T00:07:40.036192Z"
        },
        "trusted": true,
        "id": "wytB0qV_PSaj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 | Resultd And Test"
      ],
      "metadata": {
        "id": "fQ6Axpl9PSak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "last_accuracy = \"{:.3f}\".format(history.history['accuracy'][-1])\n",
        "print(\"Training Accuracy:\", last_accuracy)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-10T00:07:40.038709Z",
          "iopub.execute_input": "2023-12-10T00:07:40.039331Z",
          "iopub.status.idle": "2023-12-10T00:07:40.045016Z",
          "shell.execute_reply.started": "2023-12-10T00:07:40.039299Z",
          "shell.execute_reply": "2023-12-10T00:07:40.044147Z"
        },
        "trusted": true,
        "id": "dTWED1wyPSak"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. 1 | Plotting Model Accuracy And Loss"
      ],
      "metadata": {
        "id": "PK4upcuPPSak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Training Accuracy vs Validation Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-10T00:07:40.046644Z",
          "iopub.execute_input": "2023-12-10T00:07:40.047382Z",
          "iopub.status.idle": "2023-12-10T00:07:40.398966Z",
          "shell.execute_reply.started": "2023-12-10T00:07:40.047351Z",
          "shell.execute_reply": "2023-12-10T00:07:40.397619Z"
        },
        "trusted": true,
        "id": "r2lJeO77PSak"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Training Loss vs Validation Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-10T00:07:40.400973Z",
          "iopub.execute_input": "2023-12-10T00:07:40.401724Z",
          "iopub.status.idle": "2023-12-10T00:07:40.738538Z",
          "shell.execute_reply.started": "2023-12-10T00:07:40.401641Z",
          "shell.execute_reply": "2023-12-10T00:07:40.737237Z"
        },
        "trusted": true,
        "id": "YCxSdhijPSak"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. 2 | Test The Model"
      ],
      "metadata": {
        "id": "Dq7gnaX2PSal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_text(text):\n",
        "    tokenizer3 = Tokenizer()\n",
        "    tokenizer3.fit_on_texts(text)\n",
        "    word_index3 = tokenizer3.word_index\n",
        "\n",
        "    stemmed_wordss = [stemmer.stem(word) for word in word_index3.keys()]\n",
        "\n",
        "    tokens_list= tokenizer2.texts_to_sequences([stemmed_wordss])[0]\n",
        "\n",
        "    for i in range(len(tokens_list)):\n",
        "        for j in range(length_of_longest_sentence-len(tokens_list)):\n",
        "            tokens_list.append(0)\n",
        "    return tokens_list\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-10T00:07:40.740184Z",
          "iopub.execute_input": "2023-12-10T00:07:40.740667Z",
          "iopub.status.idle": "2023-12-10T00:07:40.750388Z",
          "shell.execute_reply.started": "2023-12-10T00:07:40.74062Z",
          "shell.execute_reply": "2023-12-10T00:07:40.74887Z"
        },
        "trusted": true,
        "id": "D4NOqt_VPSal"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        " for _ in range(5):\n",
        "    random_number = random.randint(0, 1000)\n",
        "    num_to_predicte = random_number\n",
        "\n",
        "    test = get_text([test_data['text'][num_to_predicte]])\n",
        "\n",
        "    test = np.array(test)\n",
        "    test = test.reshape(1, len(test))\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(test)\n",
        "\n",
        "    predicted_class = np.argmax(predictions)\n",
        "    print()\n",
        "    print('Random value = ',random_number)\n",
        "    print(\"Predicted Class:\", predicted_class,labels_dict.get(predicted_class))\n",
        "    print(\"Actual Class:\", test_data['label'][num_to_predicte])\n",
        "    print()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-10T00:07:40.752069Z",
          "iopub.execute_input": "2023-12-10T00:07:40.752558Z",
          "iopub.status.idle": "2023-12-10T00:07:42.006234Z",
          "shell.execute_reply.started": "2023-12-10T00:07:40.752503Z",
          "shell.execute_reply": "2023-12-10T00:07:42.005235Z"
        },
        "trusted": true,
        "id": "0Pyzy3AoPSal"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. 2 | Confusion Matrix"
      ],
      "metadata": {
        "id": "s4lZ_NkBPSal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_test_data=preprocess_data(test_data)\n",
        "\n",
        "test_X = [row[0] for row in new_train_data]\n",
        "test_y = [row[1] for row in new_train_data]\n",
        "\n",
        "for i in range(len(test_X)):\n",
        "    for j in range(length_of_longest_sentence-len(test_X[i])):\n",
        "        test_X[i].append(0)\n",
        "\n",
        "test_X = np.array(test_X)\n",
        "test_y = np.array(test_y)\n",
        "\n",
        "test_y_one_hot = to_categorical(test_y, num_classes=16000)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-10T00:07:42.007975Z",
          "iopub.execute_input": "2023-12-10T00:07:42.008917Z",
          "iopub.status.idle": "2023-12-10T00:07:42.928093Z",
          "shell.execute_reply.started": "2023-12-10T00:07:42.008872Z",
          "shell.execute_reply": "2023-12-10T00:07:42.926799Z"
        },
        "trusted": true,
        "id": "VTVuTjIfPSal"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(test_X)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-10T00:07:42.930029Z",
          "iopub.execute_input": "2023-12-10T00:07:42.930379Z",
          "iopub.status.idle": "2023-12-10T00:08:06.502503Z",
          "shell.execute_reply.started": "2023-12-10T00:07:42.930349Z",
          "shell.execute_reply": "2023-12-10T00:08:06.501472Z"
        },
        "trusted": true,
        "id": "7FftPnTnPSam"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "y_true_labels = np.argmax(test_y_one_hot, axis=1)\n",
        "\n",
        "labels=['sadness','joy','love','anger','fear','surprise']\n",
        "#labels = list(set(labels).intersection(set(np.unique(y_true_labels)).union(set(np.unique(y_pred_classes)))))\n",
        "\n",
        "cm = confusion_matrix(y_true_labels, y_pred_classes)\n",
        "df_cm = pd.DataFrame(cm, labels, labels)\n",
        "ax = sns.heatmap(df_cm, annot=True, annot_kws={'size': 16}, square=True, cbar=False, fmt='g')\n",
        "ax.set_ylim(0, 6)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "ax.invert_yaxis()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-10T00:08:06.50376Z",
          "iopub.execute_input": "2023-12-10T00:08:06.504106Z",
          "iopub.status.idle": "2023-12-10T00:08:07.255121Z",
          "shell.execute_reply.started": "2023-12-10T00:08:06.504077Z",
          "shell.execute_reply": "2023-12-10T00:08:07.254235Z"
        },
        "trusted": true,
        "id": "f4Yow0h4PSam"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LLXjslt1PW0m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}